{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 5 \u2013 Bias\u2013Variance Tradeoff\n",
        "\n",
        "This notebook implements all the steps from **lab5.md** using the `AirQualityUCI.csv` dataset.\n",
        "Run the single code cell below after placing `AirQualityUCI.csv` in the same folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CE49X \u2013 Lab 5: Bias\u2013Variance Tradeoff using the Air Quality Dataset\n",
        "# ---------------------------------------------------------------\n",
        "# 1. Load & clean AirQualityUCI data\n",
        "# 2. Use T, RH, AH to predict CO(GT)\n",
        "# 3. Train polynomial regression models (degrees 1\u201310)\n",
        "# 4. Plot training & testing error vs degree (bias\u2013variance tradeoff)\n",
        "# 5. BONUS: Use k-fold cross-validation to estimate generalization error\n",
        "# 6. Step 4: Discussion answers printed at the end\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Step 1 \u2014 Load and Prepare the Data\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# Use the CSV version (Excel is also available but not needed here)\n",
        "data_path = \"AirQualityUCI.csv\"\n",
        "\n",
        "# UCI file uses semicolon as separator and has an empty last column\n",
        "df_raw = pd.read_csv(data_path, sep=';')\n",
        "\n",
        "# Drop completely empty columns (e.g., unnamed last column)\n",
        "df_raw = df_raw.dropna(axis=1, how='all')\n",
        "\n",
        "# Replace -200 (missing data code) with NaN\n",
        "df = df_raw.replace(-200, np.nan)\n",
        "\n",
        "# Select relevant columns\n",
        "features = ['T', 'RH', 'AH']\n",
        "target = 'CO(GT)'\n",
        "\n",
        "# Keep only rows where all needed columns are present\n",
        "df_model = df[features + [target]].dropna()\n",
        "\n",
        "# Define X (features) and y (target)\n",
        "X = df_model[features].values\n",
        "y = df_model[target].values\n",
        "\n",
        "print(\"Shape of cleaned feature matrix X:\", X.shape)\n",
        "print(\"Shape of target vector y:\", y.shape)\n",
        "\n",
        "# Train\u2013test split (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", X_train.shape[0])\n",
        "print(\"Testing samples:\", X_test.shape[0])\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Step 2 \u2014 Fit Models of Increasing Complexity (degrees 1\u201310)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "degrees = list(range(1, 11))\n",
        "train_errors = []\n",
        "test_errors = []\n",
        "\n",
        "for d in degrees:\n",
        "    # Create polynomial features of degree d\n",
        "    poly = PolynomialFeatures(degree=d, include_bias=False)\n",
        "    X_train_poly = poly.fit_transform(X_train)\n",
        "    X_test_poly = poly.transform(X_test)\n",
        "\n",
        "    # Fit Linear Regression on the transformed features\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_poly, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(X_train_poly)\n",
        "    y_test_pred = model.predict(X_test_poly)\n",
        "\n",
        "    # Mean Squared Error (MSE)\n",
        "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "    train_errors.append(mse_train)\n",
        "    test_errors.append(mse_test)\n",
        "\n",
        "    print(f\"Degree {d:2d} | Train MSE: {mse_train:.4f} | Test MSE: {mse_test:.4f}\")\n",
        "\n",
        "# Find the degree with minimum test error\n",
        "best_idx = int(np.argmin(test_errors))\n",
        "best_degree = degrees[best_idx]\n",
        "print(\"\\nBest polynomial degree (min test MSE):\", best_degree)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Step 3 \u2014 Plot the Validation Curve (Bias\u2013Variance Tradeoff)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.plot(degrees, train_errors, marker='o', label='Training Error (MSE)')\n",
        "plt.plot(degrees, test_errors, marker='s', label='Testing Error (MSE)')\n",
        "\n",
        "plt.xlabel('Model Complexity (Polynomial Degree)')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xticks(degrees)\n",
        "plt.title('Bias\u2013Variance Tradeoff for Polynomial Regression on Air Quality Data')\n",
        "plt.grid(True)\n",
        "\n",
        "# Mark optimal complexity\n",
        "plt.axvline(best_degree, linestyle='--', label=f'Optimal Degree = {best_degree}')\n",
        "\n",
        "# Rough labels for underfitting / overfitting regions\n",
        "max_err = max(max(train_errors), max(test_errors))\n",
        "\n",
        "if best_degree > 1:\n",
        "    plt.text(1.05,\n",
        "             max_err * 0.9,\n",
        "             'Underfitting\\n(high bias)',\n",
        "             ha='left', va='top')\n",
        "\n",
        "if best_degree < max(degrees):\n",
        "    plt.text(best_degree + 0.5,\n",
        "             max_err * 0.9,\n",
        "             'Overfitting\\n(high variance)',\n",
        "             ha='left', va='top')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# BONUS \u2014 k-fold Cross-Validation over Model Degree\n",
        "# ---------------------------------------------------------------\n",
        "# We will use k-fold (e.g., k=5) cross-validation on the *whole* dataset\n",
        "# to estimate generalization error for each polynomial degree.\n",
        "\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "cv_means = []\n",
        "cv_stds = []\n",
        "\n",
        "for d in degrees:\n",
        "    # Build a pipeline: PolynomialFeatures -> LinearRegression\n",
        "    model = Pipeline([\n",
        "        (\"poly\", PolynomialFeatures(degree=d, include_bias=False)),\n",
        "        (\"linreg\", LinearRegression())\n",
        "    ])\n",
        "\n",
        "    # cross_val_score uses negative MSE for 'neg_mean_squared_error'\n",
        "    scores = cross_val_score(\n",
        "        model,\n",
        "        X,\n",
        "        y,\n",
        "        cv=kf,\n",
        "        scoring='neg_mean_squared_error'\n",
        "    )\n",
        "\n",
        "    # Convert negative MSE back to positive MSE\n",
        "    mse_scores = -scores\n",
        "    cv_means.append(mse_scores.mean())\n",
        "    cv_stds.append(mse_scores.std())\n",
        "\n",
        "    print(f\"[CV] Degree {d:2d} | Mean MSE: {mse_scores.mean():.4f} | Std: {mse_scores.std():.4f}\")\n",
        "\n",
        "# Plot cross-validation error vs degree\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.errorbar(\n",
        "    degrees,\n",
        "    cv_means,\n",
        "    yerr=cv_stds,\n",
        "    marker='o',\n",
        "    capsize=4,\n",
        "    label=f'{k}-fold CV Error (MSE)'\n",
        ")\n",
        "\n",
        "plt.xlabel('Model Complexity (Polynomial Degree)')\n",
        "plt.ylabel('Cross-Validated Mean Squared Error')\n",
        "plt.xticks(degrees)\n",
        "plt.title(f'{k}-fold Cross-Validation Error vs Polynomial Degree')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Step 4 \u2014 Discussion: Short Written Answers\n",
        "# ---------------------------------------------------------------\n",
        "# These answers are written in general terms, but they refer to the\n",
        "# best_degree found above and to the shapes of the curves.\n",
        "\n",
        "discussion = f\"\"\"\\\n",
        "STEP 4 \u2013 DISCUSSION\n",
        "\n",
        "1) Which polynomial degree gives the best generalization?\n",
        "\n",
        "   From the test MSE curve, the polynomial degree that gives the best\n",
        "   generalization is degree = {{best_degree}}. At this degree, the test\n",
        "   error is approximately minimal, which indicates a good balance between\n",
        "   model complexity (flexibility) and the amount of data available.\n",
        "\n",
        "2) How do the training and testing errors change as the degree increases?\n",
        "\n",
        "   As the polynomial degree increases, the training error decreases\n",
        "   monotonically or at least does not increase, because a more flexible\n",
        "   model can always fit the training data at least as well as a simpler one.\n",
        "   The testing error, however, typically first decreases (as underfitting\n",
        "   is reduced) and then starts to increase again after around degree\n",
        "   {{best_degree}}, because the model begins to overfit the noise in the\n",
        "   training set. This characteristic \u201cU\u2013shaped\u201d behavior of the test error\n",
        "   is what we see in the validation curve.\n",
        "\n",
        "3) Explain the observed behavior in terms of bias and variance.\n",
        "\n",
        "   For very low polynomial degrees, the model is too simple to capture the\n",
        "   true relationship between the features (T, RH, AH) and CO(GT). This leads\n",
        "   to high bias: both training and testing errors are relatively large, and\n",
        "   the model underfits. As we increase the degree towards {{best_degree}},\n",
        "   the bias decreases and the model fits the data better without yet having\n",
        "   very high variance, so the test error drops. For degrees higher than\n",
        "   {{best_degree}}, the variance dominates: the model becomes very sensitive\n",
        "   to small fluctuations and noise in the training data, fitting noise as if\n",
        "   it were signal. This increases the test error and corresponds to\n",
        "   overfitting (high variance, lower bias).\n",
        "\n",
        "4) Comment on how sensor noise and missing data might affect this tradeoff.\n",
        "\n",
        "   In this air quality dataset, sensor measurements (for CO, temperature,\n",
        "   humidity, etc.) can be noisy or occasionally faulty. Noise effectively\n",
        "   increases the variance of the target around the true underlying\n",
        "   relationship. Highly flexible models (high-degree polynomials) tend to\n",
        "   chase this noise, which makes overfitting worse and shifts the \u201csafe\u201d\n",
        "   complexity range to lower degrees. Missing values (such as those coded\n",
        "   as -200) reduce the amount of usable data once we drop rows with NaNs.\n",
        "   With fewer effective samples, the variance of complex models increases\n",
        "   further. Correctly handling missing data (e.g., by discarding or\n",
        "   imputing) and not letting the degree grow too large is therefore crucial\n",
        "   to obtaining a stable model that generalizes well.\n",
        "\"\"\"\n",
        "\n",
        "print(discussion)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}